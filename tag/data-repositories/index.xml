<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Data Repositories | Open Neuroscience</title><link>https://open-neuroscience.com/tag/data-repositories/</link><atom:link href="https://open-neuroscience.com/tag/data-repositories/index.xml" rel="self" type="application/rss+xml"/><description>Data Repositories</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>CC BY SA 4.0</copyright><lastBuildDate>Wed, 21 Apr 2021 00:00:00 +0000</lastBuildDate><image><url>https://open-neuroscience.com/media/openneuroscience_logo_dark.svg</url><title>Data Repositories</title><link>https://open-neuroscience.com/tag/data-repositories/</link></image><item><title>The Virtual Macaque Brain</title><link>https://open-neuroscience.com/post/the_virtual_macaque_brain/</link><pubDate>Wed, 21 Apr 2021 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/the_virtual_macaque_brain/</guid><description>&lt;p>A whole-cortex macaque structural connectome constructed from a combination of axonal tract-tracing and diffusion-weighted imaging data. Created for modeling brain dynamics using TheVirtualBrain (thevirtualbrain.org) platform. A detailed description and example usage can be found in the paper here: &lt;a href="https://www.nature.com/articles/s41597-019-0129-z">https://www.nature.com/articles/s41597-019-0129-z&lt;/a>&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Kelly Shen; Gleb Bezgin; Michael Schirner; Petra Ritter; Stefan Everling; Anthony R. McIntosh&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://zenodo.org/record/1471588#.YH8YcpNKg6d">https://zenodo.org/record/1471588#.YH8YcpNKg6d&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Kelly Shen&lt;/p>
&lt;hr></description></item><item><title>CellExplorer - Framework for analyzing single cells</title><link>https://open-neuroscience.com/post/cellexplorer_framework_for_analyzing_single_cells/</link><pubDate>Sun, 28 Mar 2021 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/cellexplorer_framework_for_analyzing_single_cells/</guid><description>&lt;p>The large diversity of cell-types of the brain, provides the means by which circuits perform complex operations. Understanding such diversity is one of the key challenges of modern neuroscience. Neurons have many unique electrophysiological and behavioral features from which parallel cell-type classification can be inferred.&lt;/p>
&lt;p>To address this, we built CellExplorer, a framework for analyzing and characterizing single cells recorded using extracellular electrodes. It can be separated into three components: a standardized yet flexible data structure, a single yet extensive processing module, and a powerful graphical interface. Through the processing module, a high dimensional representation is built from electrophysiological and functional features including the spike waveform, spiking statistics, monosynaptic connections, and behavioral spiking dynamics. The user-friendly interactive graphical interface allows for classification and exploration of those features, through a rich set of built-in plots, interaction modes, cell grouping, and filters. Powerful figures can be created for publications. Opto-tagged cells and public access to reference data have been incorporated to help you characterize your data better. The framework is built entirely in MATLAB making it fast and intuitive to implement and incorporate CellExplorer into your pipelines and analysis scripts. You can expand it with your metrics, plots, and opto-tagged data.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Peter C. Petersen, Joshua H. Siegle, Nicholas A. Steinmetz, Sara Mahallati, György Buzsáki&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://cellexplorer.org/">https://cellexplorer.org/&lt;/a>&lt;/p>
&lt;h2 id="project-video">Project Video&lt;/h2>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=GR1glNhcGIY">https://www.youtube.com/watch?v=GR1glNhcGIY&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Peter C. Petersen&lt;/p>
&lt;hr></description></item><item><title>Addgene's AAV Data Hub</title><link>https://open-neuroscience.com/post/addgene_s_aav_data_hub/</link><pubDate>Tue, 16 Mar 2021 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/addgene_s_aav_data_hub/</guid><description>&lt;p>AAV are versatile tools used by neuroscientists for expression and manipulation of neurons. Many scientists have benefited from the high-quality, ready-to-use AAV prep service from Addgene, a nonprofit plasmid repository. However, it can be challenging to determine which AAV tool and techniques are best to use for an experiment. Scientists also may have questions about how much virus to inject or which serotype or promoter should be used to target the desired neuron or brain region. To help scientists answer these questions, Addgene launched an open platform called the AAV Data Hub (&lt;a href="https://datahub.addgene.org/aav/">https://datahub.addgene.org/aav/&lt;/a>) which allows researchers to easily share practical experimental details with the scientific community (AAV used, in vivo model used, injection site, injection volumes, etc.). The goal of this platform is to help scientists find the best AAV tool for their experiments by reviewing combined data from a broad range of research labs. The AAV Data Hub launched in late 2019 and over 100 experiments have since been contributed to this project. The dataset includes details and images from experiments conducted in six different species and several different expression sites.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Addgene&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://datahub.addgene.org/aav/">https://datahub.addgene.org/aav/&lt;/a>&lt;/p>
&lt;h2 id="project-video">Project Video&lt;/h2>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=ZPKdr1RdtGI&amp;amp;feature=youtu.be">https://www.youtube.com/watch?v=ZPKdr1RdtGI&amp;amp;feature=youtu.be&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Angela Abitua&lt;/p>
&lt;hr></description></item><item><title>Collaborative Informatics and Neuroimaging Suite Toolkit for Anonymous Computation (COINSTAC)</title><link>https://open-neuroscience.com/post/collaborative_informatics_and_neuroimaging_suite_toolkit_for_anonymous_computation_coinstac_/</link><pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/collaborative_informatics_and_neuroimaging_suite_toolkit_for_anonymous_computation_coinstac_/</guid><description>&lt;p>COINSTAC provides a platform to analyze data stored locally across multiple organizations without the need for pooling the data at any point during the analysis. It is intended to be an ultimate one-stop shop by which researchers can build any statistical or machine learning model collaboratively in a decentralized fashion. This framework implements a message passing infrastructure that will allow large scale analysis of decentralized data with results on par with those that would have been obtained if the data were in one place.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Sergey M. Plis; Anand D. Sarwate; Dylan Wood; Christopher Dieringer; Drew Landis; Cory Reed; Sandeep R. Panta; Jessica A. Turner; Jody M. Shoemaker; Kim W. Carter; Paul Thompson; Kent Hutchison; Vince D. Calhoun&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://github.com/trendscenter/coinstac">https://github.com/trendscenter/coinstac&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Kelly Rootes-Murdy&lt;/p>
&lt;hr></description></item><item><title>INCF KnowledgeSpace</title><link>https://open-neuroscience.com/post/incf_knowledgespace/</link><pubDate>Wed, 30 Sep 2020 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/incf_knowledgespace/</guid><description>&lt;p>KnowledgeSpace aims to be a globally-used, community-based, data-driven encyclopedia for neuroscience that links brain research concepts to data, models, and the literature that support them. Further it aims to serve as a framework where large-scale neuroscience projects can expose their data to the neuroscience community-at-large. KnowledgeSpace is a framework that combines general descriptions of neuroscience concepts found in wikipedia with more detailed content from NeuroLex. It then integrates the content from those two sources with the latest neuroscience citations found in PubMed and data found in some of the world’s leading neuroscience repositories. KnowledgeSpace is a joint development between the Human Brain Project (HBP), the International Neuroinformatics Coordinating Facility (INCF), and the Neuroscience Information Framework (NIF).&lt;/p>
&lt;p>KnowledgeSpace is currently being developed with funding from the European Union&amp;rsquo;s Horizon 2020 Framework Programme for Research and Innovation under the Specific Grant Agreement No. 945539 (Human Brain Project SGA3), INCF, and Neuroscience Information Framework (NIF). Earlier development was supported by the European Union&amp;rsquo;s Horizon 2020 Framework Programme for Research and Innovation under the Framework Partnership Agreement No. 650003 (HBP FPA), INCF, NIF, and the Blue Brain Project.&lt;/p>
&lt;p>KS builds on a vocabulary service, populated with an integrated set of neuroscience ontologies with initial content coming from the Neuroscience Lexicon (NeuroLex), and the Brain Architecture Management System (BAMS). It links to an expanding set of data sources through the NIF federated search infrastructure.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>INCF team&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://knowledge-space.org">https://knowledge-space.org&lt;/a>&lt;/p>
&lt;h2 id="project-video">Project Video&lt;/h2>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=GQCGZOPLED0">https://www.youtube.com/watch?v=GQCGZOPLED0&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Malin Sandström&lt;/p>
&lt;hr></description></item><item><title>Neuroimaging Informatics Tools and Resources Collaboratory (NITRC)</title><link>https://open-neuroscience.com/post/neuroimaging_informatics_tools_and_resources_collaboratory_nitrc/</link><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/neuroimaging_informatics_tools_and_resources_collaboratory_nitrc/</guid><description>&lt;p>NeuroImaging Tools &amp;amp; Resources Collaboratory is an award-winning free web-based resource that offers comprehensive information on an ever expanding scope of neuroinformatics software and data. Since debuting in 2007, NITRC has helped the neuroscience community make further discoveries using software and data produced from research that used to end up lost or disregarded.&lt;/p>
&lt;p>NITRC also provides free access to data and enables pay-per-use cloud-based access to unlimited computing power, enabling worldwide scientific collaboration with minimal startup and cost. NITRC’s scientific focus includes: MR, PET/SPECT, CT, EEG/MEG, optical imaging, clinical neuroimaging, computational neuroscience, and imaging genomics software tools, data, and computational resources.&lt;/p>
&lt;p>With NITRC and its components—the Resources Registry (NITRC-R), Image Repository (NITRC-IR), and Computational Environment (NITRC-CE)—a researcher can obtain pilot or proof-of-concept data to validate a hypothesis for just a few dollars.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>NITRC Development Team&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="http://www.nitrc.org">http://www.nitrc.org&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
David Kennedy&lt;/p>
&lt;hr></description></item><item><title>ReproNim: A Center for Reproducible Neuroimaging Computation</title><link>https://open-neuroscience.com/post/repronim_a_center_for_reproducible_neuroimaging_computation/</link><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/repronim_a_center_for_reproducible_neuroimaging_computation/</guid><description>&lt;p>ReproNim&amp;rsquo;s goal is to improve the reproducibility of neuroimaging science and extend the value of our national investment in neuroimaging research, while making the process easier and more efficient for investigators.&lt;/p>
&lt;p>ReproNim delivers a reproducible analysis framework comprised of components that include: 1) data and software discovery; 2) implementation of standardized description of data, results and workflows; 3) development of execution options that facilitates operation in all computational environments; 4)
provision of training and education to the community.&lt;/p>
&lt;p>All components of the framework are intended to foster continued use and development of the reproducible and generalizable framework in neuroimaging research.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>The ReproNim Development Team&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://github.com/ReproNim">https://github.com/ReproNim&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
David Kennedy&lt;/p>
&lt;hr></description></item><item><title>Simple Behavioral Analysis (SimBA)</title><link>https://open-neuroscience.com/post/simple_behavioral_analysis_simba/</link><pubDate>Thu, 23 Jul 2020 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/simple_behavioral_analysis_simba/</guid><description>&lt;p>Several excellent computational frameworks exist that enable high-throughput and consistent tracking of freely moving unmarked animals. SimBA introduce and distribute a plug-and play pipeline that enables users to use these pose-estimation approaches in combination with behavioral annotation for the generation of supervised machine-learning behavioral predictive classifiers.&lt;/p>
&lt;p>SimBA was developed for the analysis of complex social behaviors, but includes the flexibility for users to generate predictive classifiers across other behavioral modalities with minimal effort and no specialized computational background.&lt;/p>
&lt;p>SimBA has a variety of extended functions for large scale batch video pre-processing, generating descriptive statistics from movement features, and interactive modules for user-defined regions of interest and visualizing classification probabilities and movement patterns.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Simon Nilsson: Jia Jie Chhong; Sophia Hwang; Nastacia Goodwin; Sam A Golden&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://github.com/sgoldenlab/simba">https://github.com/sgoldenlab/simba&lt;/a>&lt;/p>
&lt;h2 id="project-video">Project Video&lt;/h2>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=Frq6mMcaHBc&amp;amp;list=PLi5Vwf0hhy1R6NDQJ3U28MOUJPfl2YWYl&amp;amp;index=2&amp;amp;t=0s">https://www.youtube.com/watch?v=Frq6mMcaHBc&amp;amp;list=PLi5Vwf0hhy1R6NDQJ3U28MOUJPfl2YWYl&amp;amp;index=2&amp;amp;t=0s&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Simon Nilsson&lt;/p>
&lt;hr></description></item><item><title>OpenNeuro</title><link>https://open-neuroscience.com/post/openneuro/</link><pubDate>Tue, 14 Jul 2020 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/openneuro/</guid><description>&lt;p>A free and open platform for sharing MRI, MEG, EEG, iEEG, and ECoG data.&lt;/p>
&lt;p>With OpenNeuro, you can:&lt;/p>
&lt;ul>
&lt;li>Browse and explore public datasets and analyses from a wide range of global contributors. Our collection of public datasets continues to grow as more and more become BIDS compatible.&lt;/li>
&lt;li>Download and use public data to create new datasets and run your own analyses.&lt;/li>
&lt;li>Privately share your data so your colleagues can view and edit your work.&lt;/li>
&lt;li>Publish your dataset where anyone can view, download, and run analyses on it.&lt;/li>
&lt;li>Create snapshots of your datasets to ensure past analyses remain reproducible as your datasets grow and change. Publish any of your snapshots while you continue work on your original data behind the scenes.&lt;/li>
&lt;li>Explore your published OpenNeuro dataset using BrainLife&amp;rsquo;s computing network. Utilize their community driven apps to run a variety of analysis and processing software in the browser.&lt;/li>
&lt;/ul>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Russell A. Poldrack; Krzysztof Jacek Gorgolewski&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://openneuro.org/">https://openneuro.org/&lt;/a>&lt;/p>
&lt;h2 id="project-video">Project Video&lt;/h2>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=FK_c1x1Pilk">https://www.youtube.com/watch?v=FK_c1x1Pilk&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Elizabeth DuPre&lt;/p>
&lt;hr></description></item><item><title>BossDB</title><link>https://open-neuroscience.com/post/bossdb/</link><pubDate>Tue, 26 May 2020 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/bossdb/</guid><description>&lt;p>BossDB is a volumetric database that lives in the AWS cloud. Hundreds of terabytes of electron microscopy, light microscopy, and x-ray tomography data are available for free download and study.&lt;/p>
&lt;p>Have a project you want to share with the world for free? Get in touch!
&lt;a href="https://twitter.com/thebossdb">https://twitter.com/thebossdb&lt;/a>&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>JHU|APL&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://bossdb.org/">https://bossdb.org/&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Jordan Matelsky&lt;/p>
&lt;hr></description></item></channel></rss>