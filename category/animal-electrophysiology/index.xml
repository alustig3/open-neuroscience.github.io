<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Animal electrophysiology | Open Neuroscience</title><link>https://open-neuroscience.com/category/animal-electrophysiology/</link><atom:link href="https://open-neuroscience.com/category/animal-electrophysiology/index.xml" rel="self" type="application/rss+xml"/><description>Animal electrophysiology</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><copyright>CC BY SA 4.0</copyright><lastBuildDate>Sat, 13 Mar 2021 00:00:00 +0000</lastBuildDate><image><url>https://open-neuroscience.com/media/openneuroscience_logo_dark.svg</url><title>Animal electrophysiology</title><link>https://open-neuroscience.com/category/animal-electrophysiology/</link></image><item><title>Heuristic Spike Sorting Tuner (HSST)</title><link>https://open-neuroscience.com/post/heuristic_spike_sorting_tuner_hsst_/</link><pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/heuristic_spike_sorting_tuner_hsst_/</guid><description>&lt;p>Extracellular microelectrodes frequently record neural activity from more than one neuron in the vicinity of the electrode. The process of labeling each recorded spike waveform with the identity of its source neuron is called spike sorting and is often approached from an abstracted statistical perspective. However, these approaches do not consider neurophysiological realities and may ignore important features that could improve the accuracy of these methods. Further, standard algorithms typically require selection of at least one free parameter, which can have significant effects on the quality of the output. We describe a Heuristic Spike Sorting Tuner (HSST) that determines the optimal choice of the free parameters for a given spike sorting algorithm based on the neurophysiological qualification of unit isolation and signal discrimination. A set of heuristic metrics are used to score the output of a spike sorting algorithm over a range of free parameters resulting in optimal sorting quality. We demonstrate that these metrics can be used to tune parameters in several spike sorting algorithms. The HSST algorithm shows robustness to variations in signal to noise ratio, number and relative size of units per channel. Moreover, the HSST algorithm is computationally efficient, operates unsupervised, and is parallelizable for batch processing.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>David A. Bjanes; Lee B. Fisher; Robert A. Gaunt; Douglas J. Weber&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://github.com/davidbjanes/hsst">https://github.com/davidbjanes/hsst&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
David Bjanes&lt;/p>
&lt;hr></description></item><item><title>OPETH: Open Source Solution for Real-Time Peri-Event Time Histogram Based on Open Ephys</title><link>https://open-neuroscience.com/post/opeth_open_source_solution_for_real_time_peri_event_time_histogram_based_on_open_ephys/</link><pubDate>Sat, 13 Mar 2021 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/opeth_open_source_solution_for_real_time_peri_event_time_histogram_based_on_open_ephys/</guid><description>&lt;p>Single cell electrophysiology remains one of the most widely used approaches of systems neuroscience. Decisions made by the experimenter during electrophysiology recording largely determine recording quality, duration of the project and value of the collected data. Therefore, online feedback aiding these decisions can lower monetary and time investment, and substantially speed up projects as well as allow novel studies otherwise not possible due to prohibitively low throughput. Real-time feedback is especially important in studies that involve optogenetic cell type identification by enabling a systematic search for neurons of interest. However, such tools are scarce and limited to costly commercial systems with high degree of specialization, which hitherto prevented wide-ranging benefits for the community. To address this, we present an open-source tool that enables online feedback during electrophysiology experiments and provides a Python interface for the widely used Open Ephys open source data acquisition system. Specifically, our software allows flexible online visualization of spike alignment to external events, called the online peri-event time histogram (OPETH). These external events, conveyed by digital logic signals, may indicate photostimulation time stamps for in vivo optogenetic cell type identification or the times of behaviorally relevant events during in vivo behavioral neurophysiology experiments. Therefore, OPETH allows real-time identification of genetically defined neuron types or behaviorally responsive populations. By allowing &amp;ldquo;hunting&amp;rdquo; for neurons of interest, OPETH significantly reduces experiment time and thus increases the efficiency of experiments that combine in vivo electrophysiology with behavior or optogenetic tagging of neurons.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>András Széll; Sergio Martínez-Bellver; Panna Hegedüs; Balázs Hangya&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://github.com/hangyabalazs/opeth">https://github.com/hangyabalazs/opeth&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Balazs Hangya&lt;/p>
&lt;hr></description></item><item><title>SignalBuddy</title><link>https://open-neuroscience.com/post/signalbuddy/</link><pubDate>Tue, 23 Feb 2021 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/signalbuddy/</guid><description>&lt;p>SignalBuddy is an easy-to-make, easy-to-use signal generator for scientific applications. Making friends is hard, but making SignalBuddy is easy. All you need is an Arduino Uno! SignalBuddy replaces more complicated and (much) more expensive signal generators in laboratory settings where one millisecond resolution is sufficient.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Richard Warren&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://hackaday.io/project/167649-signalbuddy">https://hackaday.io/project/167649-signalbuddy&lt;/a>&lt;/p>
&lt;h2 id="project-video">Project Video&lt;/h2>
&lt;p>&lt;a href="https://github.com/richard-warren/SignalBuddy/raw/master/images/SignalBuddy3D.gif">https://github.com/richard-warren/SignalBuddy/raw/master/images/SignalBuddy3D.gif&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Richard Warren&lt;/p>
&lt;hr></description></item><item><title>Open Source Tools for Temporally Controlled Rodent Behavior Suitable for Electrophysiology and Optogenetic Manipulations</title><link>https://open-neuroscience.com/post/open_source_tools_for_temporally_controlled_rodent_behavior_suitable_for_electrophysiology_and_optogenetic_manipulations/</link><pubDate>Fri, 22 Jan 2021 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/open_source_tools_for_temporally_controlled_rodent_behavior_suitable_for_electrophysiology_and_optogenetic_manipulations/</guid><description>&lt;p>Understanding how the brain controls behavior requires observing and manipulating neural activity in awake behaving animals. Neuronal firing is timed at millisecond precision. Therefore, to decipher temporal coding, it is necessary to monitor and control animal behavior at the same level of temporal accuracy. However, it is technically challenging to deliver sensory stimuli and reinforcers as well as to read the behavioral responses they elicit with millisecond precision. Presently available commercial systems often excel in specific aspects of behavior control, but they do not provide a customizable environment allowing flexible experimental design while maintaining high standards for temporal control necessary for interpreting neuronal activity. Moreover, delay measurements of stimulus and reinforcement delivery are largely unavailable. We combined microcontroller-based behavior control with a sound delivery system for playing complex acoustic stimuli, fast solenoid valves for precisely timed reinforcement delivery and a custom-built sound attenuated chamber using high-end industrial insulation materials. Together this setup provides a physical environment to train head-fixed animals, enables calibrated sound stimuli and precisely timed fluid and air puff presentation as reinforcers. We provide latency measurements for stimulus and reinforcement delivery and an algorithm to perform such measurements on other behavior control systems. Combined with electrophysiology and optogenetic manipulations, the millisecond timing accuracy will help interpret temporally precise neural signals and behavioral changes. Additionally, since software and hardware provided here can be readily customized to achieve a large variety of paradigms, these solutions enable an unusually flexible design of rodent behavioral experiments.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Nicola Solari; Katalin Sviatkó; Tamás Laszlovszky; Panna Hegedüs; Balázs Hangya&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://github.com/hangyabalazs/Rodent_behavior_setup">https://github.com/hangyabalazs/Rodent_behavior_setup&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Balazs Hangya&lt;/p>
&lt;hr></description></item><item><title>Mouse VR</title><link>https://open-neuroscience.com/post/mouse_vr/</link><pubDate>Sun, 04 Oct 2020 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/mouse_vr/</guid><description>&lt;p>Harvey Lab miniaturized mouse VR rig for head-fixed virtual navigation and decision-making tasks.&lt;/p>
&lt;p>The VR setup is comprised of several independent assemblies:&lt;/p>
&lt;p>The screen assembly: a laser projector projects onto a parabolic screen surrounding the mouse. This is the basis for the visual virtual reality.&lt;/p>
&lt;p>Ball cup assembly: an air-supported 8&amp;quot; styrofoam ball that the mouse can run on, with associated ball cup, sensors, and electronics&lt;/p>
&lt;p>Reward delivery system and lick sensor: lick spout, liquid reward reservoir, solenoid, and associated electronics&lt;/p>
&lt;p>Enclosure: A box surrounding the behavioral setup.&lt;/p>
&lt;p>Each of these components is independent of the others: i.e. just the screen could be used in combination with a different treadmill and reward delivery system. The electronics for the ball sensors, reward delivery, and lick detection are all mounted on the same PCB. If only one or two of these functions are needed, you do not need to populate the entire PCB.&lt;/p>
&lt;p>The screen assembly is designed to be small enough to be mounted within a standard 19&amp;quot; server rack, which could easily fit 3 rigs stacked vertically (or two + monitor and keyboard station).&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Noah Pettit; Matthias Minderer; Selmaan Chettih; Charlotte Arlt; Jim Bohnslav; Pavel Gorelick; Ofer Mazor; Christopher Harvey&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://github.com/HarveyLab/mouseVR">https://github.com/HarveyLab/mouseVR&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Noah Pettit&lt;/p>
&lt;hr></description></item><item><title>DataJoint</title><link>https://open-neuroscience.com/post/datajoint/</link><pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/datajoint/</guid><description>&lt;p>DataJoint is an open-source library for managing and sharing scientific data pipelines in Python and Matlab.&lt;/p>
&lt;p>DataJoint allows creating and sharing computational data pipelines, which are defined as databases and analysis code for executing steps of activities for data collection and analysis. For example, many neuroscience studies are organized around DataJoint pipelines that start with basic information about the experiment, then ingest acquired data, and then perform processing, analysis, and visualization of results. The entire pipeline is diagrammed as a graph where each node is a table in the database with a corresponding class in the programming language; together they define the data structure and computations.&lt;/p>
&lt;p>DataJoint key features include:&lt;/p>
&lt;ul>
&lt;li>access to shared data pipelines in a relational database (MySQL-compatible) from Python, Matlab, or both.&lt;/li>
&lt;li>data integrity and consistency based founded on the relational data model and transactions&lt;/li>
&lt;li>an intuitive data definition language for pipeline design&lt;/li>
&lt;li>a diagramming notation to visualize data structure and dependencies&lt;/li>
&lt;li>a serialization framework: storing large numerical arrays and other scientific data in a language-independent way&lt;/li>
&lt;li>a flexible query language to retrieve precise cross-sections of data in a desired format&lt;/li>
&lt;li>automated execution of computational jobs, with built-in job management for distributed computing&lt;/li>
&lt;li>managed storage of large data objects outside the database&lt;/li>
&lt;/ul>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Dimitri Yatsenko; Edgar Walker; Fabian Sinz; Christopher Turner; Raphael Guzman&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://datajoint.io">https://datajoint.io&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Dimitri Yatsenko&lt;/p>
&lt;hr></description></item><item><title>Neurodata Without Borders</title><link>https://open-neuroscience.com/post/neurodata_without_borders/</link><pubDate>Sun, 19 Jul 2020 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/neurodata_without_borders/</guid><description>&lt;p>Neurodata Without Borders is a data standard for neurophysiology, providing neuroscientists with a common standard to share, archive, use, and build analysis tools for neurophysiology data. NWB is designed to store a variety of neurophysiology data, including data from intracellular and extracellular electrophysiology experiments, data from optical physiology experiments, and tracking and stimulus data.&lt;/p>
&lt;p>The NWB team consists of neuroscientists and software developers who recognize that adoption of a unified data format is an important step toward breaking down the barriers to data sharing in neuroscience.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Andrew Tritt; Ryan Ly; Ben Dichter; Oliver Ruebel&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://www.nwb.org/">https://www.nwb.org/&lt;/a>&lt;/p>
&lt;h2 id="project-video">Project Video&lt;/h2>
&lt;p>&lt;a href="https://youtu.be/vfQsMyl0HQI">https://youtu.be/vfQsMyl0HQI&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Ben Dichter&lt;/p>
&lt;hr></description></item><item><title>SpikeInterface</title><link>https://open-neuroscience.com/post/spikeinterface/</link><pubDate>Wed, 01 Jul 2020 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/spikeinterface/</guid><description>&lt;p>SpikeInterface is a unified Python framework for spike sorting. With its high-level API, it is designed to be accessible and easy to use, allowing users to build full analysis pipelines for spike sorting (reading-writing (IO) / preprocessing / spike sorting / postprocessing / validation / curation / comparison / visualization) with a few lines of code.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Alessio Buccino*; Cole Hurwitz*; Samuel Garcia; Jeremy Magland; Josh Siegle; Matthias Hennig&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://github.com/SpikeInterface/spikeinterface">https://github.com/SpikeInterface/spikeinterface&lt;/a>&lt;/p>
&lt;h2 id="project-video">Project Video&lt;/h2>
&lt;p>&lt;a href="https://www.youtube.com/watch?v=nWJGwFB7oII">https://www.youtube.com/watch?v=nWJGwFB7oII&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Alessio Buccino&lt;/p>
&lt;hr></description></item><item><title>Craniobot</title><link>https://open-neuroscience.com/post/craniobot/</link><pubDate>Fri, 22 May 2020 00:00:00 +0000</pubDate><guid>https://open-neuroscience.com/post/craniobot/</guid><description>&lt;p>The Craniobot is a cranial microsurgery platform that combines automated skull surface profiling with a computer numerical controlled (CNC) milling machine to perform a variety of cranial microsurgical procedures in mice. The Craniobot utilizes a low force contact sensor to profile the skull surface and uses this information to perform micrometer-scale precise milling operations within minutes. The procedure of removing the sub-millimeter thick mouse skull precisely without damaging the underlying brain can be technically challenging and often takes significant skill and practice. This can now be overcome using the Craniobot.&lt;/p>
&lt;h2 id="project-authors">Project Author(s)&lt;/h2>
&lt;p>Mathew Rynes, Leila Ghanbari, Micheal Laroque, Greg Johnson, Daniel Sousa Schulman, Suhasa Kodandaramaiah&lt;/p>
&lt;h2 id="project-links">Project Links&lt;/h2>
&lt;p>&lt;a href="https://www.labmaker.org/products/craniobot">https://www.labmaker.org/products/craniobot&lt;/a>&lt;/p>
&lt;hr>
&lt;p>This post was automatically generated by
Matias Andina&lt;/p>
&lt;hr></description></item></channel></rss>